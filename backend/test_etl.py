from backend.etl.xml_parser import limpiar_xmls_en_carpeta, parsear_xmls_en_carpeta
from backend.etl.clasificador import dividir_en_bloques, clasificar_lote
from backend.etl.supabase_client import subir_dataframe
from backend.config import get_directories
import pandas as pd

def test_pipeline_completo():
    """
    Ejecuta el flujo completo:
    1. Limpia XMLs
    2. Parsea √≠tems con metadata
    3. Clasifica usando GPT
    4. Une clasificaci√≥n
    5. Sube a Supabase
    """
    carpeta_descarga, _ = get_directories()

    print("üßº Limpiando XMLs...")
    limpiar_xmls_en_carpeta(carpeta_descarga)

    print("üìÑ Parseando XMLs...")
    registros = parsear_xmls_en_carpeta(carpeta_descarga)
    if not registros:
        print("‚ùå No se encontraron registros.")
        return

    for i, r in enumerate(registros):
        r["rowid"] = i + 1

    print("ü§ñ Clasificando √≠tems...")
    clasificados = []
    for bloque in dividir_en_bloques(registros, 100):
        clasificados.extend(clasificar_lote(bloque))

    df_items = pd.DataFrame(registros)
    df_clasificacion = pd.DataFrame(clasificados)
    df_final = df_items.merge(df_clasificacion, on="rowid", how="left")

    print(f"‚úÖ Total √≠tems clasificados: {len(df_final)}")
    print(df_final[["fecha", "proveedor", "descripcion", "monto_item", "categoria"]].head())

    print("‚¨ÜÔ∏è Subiendo a Supabase...")
    subir_dataframe(df_final)

if __name__ == "__main__":
    test_pipeline_completo()
